"""
Enhanced ML Model Manager - Additional Features from trading_system2  
trading_system2ì˜ í–¥ìƒëœ ML ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ê¸°ì¡´ ì‹œìŠ¤í…œì— ì¶”ê°€
"""

import asyncio
import logging
from functools import lru_cache
from typing import Dict, Any, List
import hashlib
import time


class EnhancedMLModelManager:
    """
    trading_system2ì—ì„œ ê°€ì ¸ì˜¨ í–¥ìƒëœ ML ëª¨ë¸ ë§¤ë‹ˆì €
    ê¸°ì¡´ ë³µí•©ì ì¸ ML ì‹œìŠ¤í…œì— ì¶”ê°€ì ì¸ ì•ˆì „ì„±ê³¼ ë‹¨ìˆœì„±ì„ ì œê³µ
    """
    
    def __init__(self, models: dict):
        self.models = models
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # ì„±ëŠ¥ ìµœì í™”: ìºì‹œ ë° ë°°ì¹˜ ì²˜ë¦¬
        self._prediction_cache = {}
        self._cache_ttl = {}
        self._cache_timeout = 300  # 5ë¶„ ìºì‹œ
        
        # ë°°ì¹˜ ì²˜ë¦¬ í†µê³„
        self._batch_stats = {
            'total_batches': 0,
            'successful_batches': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
    @lru_cache(maxsize=128)
    def _get_cached_prediction(self, symbol: str, data_hash: str) -> Dict[str, Any]:
        """LRU ìºì‹œë¥¼ í™œìš©í•œ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹±"""
        return self._internal_predict(symbol)
    
    def _internal_predict(self, symbol: str) -> Dict[str, Any]:
        """ë‚´ë¶€ ì˜ˆì¸¡ ë¡œì§"""
        model = self.models.get(symbol)
        if model is None:
            return {"prediction": "neutral", "confidence": 0.0}
            
        result = model.predict() if hasattr(model, 'predict') else {}
        confidence = result.get("confidence") or result.get("avg_confidence", 0.0)
        
        return {
            "prediction": result.get("prediction", "neutral"),
            "confidence": float(confidence) if confidence else 0.0,
            "source": "enhanced_ml_manager"
        }

    def get_predictions(self, symbol: str) -> Dict[str, Any]:
        """
        í–¥ìƒëœ ì˜ˆì¸¡ ê¸°ëŠ¥ - ìºì‹± ì§€ì›
        """
        try:
            # ìºì‹œ í‚¤ ìƒì„± (ë°ì´í„° í•´ì‹œ ê¸°ë°˜)
            current_time = int(time.time())
            cache_key = f"{symbol}:{current_time // 60}"  # 1ë¶„ ë‹¨ìœ„ ìºì‹œ
            data_hash = hashlib.md5(cache_key.encode()).hexdigest()[:8]
            
            # ìºì‹œëœ ê²°ê³¼ í™•ì¸
            if symbol in self._prediction_cache and current_time < self._cache_ttl.get(symbol, 0):
                self._batch_stats['cache_hits'] += 1
                self.logger.debug(f"ğŸ¯ {symbol} ìºì‹œ íˆíŠ¸: {data_hash}")
                return self._prediction_cache[symbol]
            
            # ìºì‹œ ë¯¸ìŠ¤ - ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
            self._batch_stats['cache_misses'] += 1
            self.logger.debug(f"ğŸ”„ {symbol} ìºì‹œ ë¯¸ìŠ¤, ìƒˆ ì˜ˆì¸¡ ìˆ˜í–‰: {data_hash}")
            
            model = self.models.get(symbol)
            if model is None:
                self.logger.warning(f"âš ï¸ {symbol} ëª¨ë¸ ì—†ìŒ, neutral ê¸°ë³¸ê°’ ë°˜í™˜")
                return {"prediction": "neutral", "confidence": 0.0}
                
            # ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
            result = model.predict() if hasattr(model, 'predict') else {}
            
            # confidence ì ìˆ˜ ì •ê·œí™”
            confidence = result.get("confidence") or result.get("avg_confidence", 0.0)
            
            prediction_result = {
                "prediction": result.get("prediction", "neutral"),
                "confidence": float(confidence) if confidence else 0.0,
                "source": "enhanced_ml_manager",
                "cached": False,
                "timestamp": current_time
            }
            
            # ìºì‹œì— ì €ì¥
            self._prediction_cache[symbol] = prediction_result
            self._cache_ttl[symbol] = current_time + self._cache_timeout
            
            self.logger.debug(f"ğŸ“Š {symbol} ì˜ˆì¸¡ ì™„ë£Œ (ìºì‹œ ì €ì¥): {prediction_result}")
            return prediction_result
            
        except Exception as e:
            self.logger.error(f"âŒ {symbol} ì˜ˆì¸¡ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"prediction": "neutral", "confidence": 0.0, "error": str(e)}
    
    async def batch_predictions(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        ë°°ì¹˜ ML ì˜ˆì¸¡ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
        """
        if not symbols:
            return {}
        
        try:
            self._batch_stats['total_batches'] += 1
            start_time = time.time()
            
            self.logger.info(f"ğŸš€ ë°°ì¹˜ ì˜ˆì¸¡ ì‹œì‘: {len(symbols)}ê°œ ì‹¬ë³¼")
            
            # ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
            tasks = [self._async_predict(symbol) for symbol in symbols]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì •ë¦¬
            batch_result = {}
            success_count = 0
            
            for symbol, result in zip(symbols, results):
                if isinstance(result, Exception):
                    self.logger.error(f"âŒ {symbol} ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {result}")
                    batch_result[symbol] = {"prediction": "neutral", "confidence": 0.0, "error": str(result)}
                else:
                    batch_result[symbol] = result
                    success_count += 1
            
            processing_time = time.time() - start_time
            success_rate = success_count / len(symbols) * 100
            
            if success_count == len(symbols):
                self._batch_stats['successful_batches'] += 1
            
            self.logger.info(f"âœ… ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {success_count}/{len(symbols)} ì„±ê³µ ({success_rate:.1f}%, {processing_time:.2f}ì´ˆ)")
            
            return batch_result
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}", exc_info=True)
            return {symbol: {"prediction": "neutral", "confidence": 0.0, "error": str(e)} for symbol in symbols}
    
    async def _async_predict(self, symbol: str) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì˜ˆì¸¡ ë˜í¼"""
        return self.get_predictions(symbol)
            
    def get_simple_prediction(self, symbol: str) -> str:
        """
        ë‹¨ìˆœí™”ëœ ì˜ˆì¸¡ ê²°ê³¼ - ë³µì¡í•œ ì‹œìŠ¤í…œì—ì„œ ë¹ ë¥¸ ê²°ì •ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©
        """
        try:
            result = self.get_predictions(symbol)
            return result.get("prediction", "neutral")
        except:
            return "neutral"
            
    def is_model_available(self, symbol: str) -> bool:
        """
        ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ìœ í‹¸ë¦¬í‹°
        """
        return symbol in self.models and self.models[symbol] is not None
        
    def get_available_models(self) -> list:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        """
        return [symbol for symbol, model in self.models.items() if model is not None]